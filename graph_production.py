# -*- coding: utf-8 -*-
"""graph_production.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/194x7wEVUuTTkm7rjKAsZSvI8tcGdLTVz
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/Research/DASH

!pip install plotly
!pip install -U kaleido

import pandas as pd
import plotly.graph_objects as go
import plotly.subplots as sp
import plotly.express as px
import kaleido

metadata_fields = ['num_node', 'average_degree', 'weight_range', 'test_id', 'weight_scale', 'time_created', 'num_edge', 'weight_range/scale']
REDUCTION_FACTORS = [2, 3, 4, 6, 8, 11, 16, 23, 32, 45]
samplers = ['gurobi', 'dwave'] + [f'fl {division} 10000 0' for division in REDUCTION_FACTORS]
                                          
energies = pd.read_csv("results/energy.csv")
print(energies.columns)
opt_gap = pd.DataFrame()

for colname in energies.columns: 
    if colname in samplers: 
        opt_gap[colname] = (1 - energies[colname] / energies['gurobi']) * 100
    if colname in metadata_fields: 
        opt_gap[colname] = energies[colname]

print(opt_gap.query('num_node == 60 and average_degree == 6 and weight_scale == 32 and weight_range == 1024'))

qubits = pd.read_csv("results/qubits.csv")
print(qubits.columns)
size_expansion = pd.DataFrame()

for colname in qubits.columns: 
    if colname in samplers and colname != 'gurobi': 
        size_expansion[colname] = qubits[colname] / qubits['dwave'] 
    if colname in metadata_fields: 
        size_expansion[colname] = qubits[colname]

print(size_expansion.query('num_node == 60 and average_degree == 6 and weight_scale == 32 and weight_range == 1024'))

running_times = pd.read_csv("results/running_time.csv")
print(running_times.columns)

from pandas.core.arrays.timedeltas import Tick
import matplotlib.ticker as ticker

default_sampler = {
    "sampler_names": [ 'fl 11 10000 0','dwave', 'gurobi'],
    "sampler_labels": ['HamSlicing+QA', 'QA', 'IQP (Gurobi)']
}

default_marker_sequence = [
    dict(size=20, opacity = 0.75, symbol='cross'),
    dict(size=20, opacity = 0.75, symbol='x'),
    dict(size=20, opacity = 0.75, symbol='circle-open'),
    dict(size=20, opacity = 0.75, symbol='square-open'),
    dict(size=20, opacity = 0.75, symbol='star')
]

default_color_sequence=px.colors.qualitative.Dark2
fig = px.colors.qualitative.swatches()
fig.show()
default_layout = {
    "height":600, 
    "width":800, 
    "font": dict(size=32), 
    "plot_bgcolor":'white',
    "legend": dict(
      yanchor="top",
      y=0.99,
      xanchor="left",
      x=0.01,
      bgcolor="rgba(0,0,0,0)"
      ),
    "colorway":default_color_sequence,
    "margin": dict(l=50, r=50, t=50, b=50)
  }

def plot_all_solvers(
    df = opt_gap, 
    variable_name = 'num_node', 
    variable_label = 'Number of variables', 
    quantity_label = 'Optimality gap (%)', 
    chart_types = ['mean', 'mean', 'mean'], 
    sampler_names = default_sampler["sampler_names"], 
    sampler_labels = default_sampler["sampler_labels"], 
    fig_fpath = "./plots/fig.pdf",
    layout = {},
    marker_sequence = default_marker_sequence,
    verbose = False, # Print out the info
): 
    DEFAULT_FILTERS = {
        'num_node': 60, 
        'average_degree': 6, 
        'weight_range': 1024, 
        'weight_scale': 32
    }
    filter_str = ''
    for filter_key in DEFAULT_FILTERS.keys(): 
        if filter_key != variable_name: 
            if len(filter_str) > 0: 
                filter_str += ' and '
            filter_str += filter_key + ' == ' + str(DEFAULT_FILTERS[filter_key])

    print("Filter string: ", filter_str)
    df_by_variable = df.query(filter_str)[[variable_name] + sampler_names]
    print(df_by_variable)
    
    df_mean = df_by_variable.groupby(variable_name, as_index=False).aggregate('mean')
    


    fig = sp.make_subplots(
        rows=1, 
        cols=1, 
    )

    #fig.update_annotations(font_size=72)


    for (sampler_name, sampler_label, chart_type) in zip(sampler_names, sampler_labels, chart_types): 
      fig.add_trace(
          go.Scatter(x = df_mean[variable_name], y = df_mean[sampler_name], mode='lines+markers', name=sampler_label) if chart_type == 'mean'
          else go.Scatter(x = df_by_variable[variable_name], y = df_by_variable[sampler_name], mode='markers', name=sampler_label), 
          row=1, 
          col=1
      )
    if verbose:
      print(fig.data)

    fig.update_xaxes(
        title_text=variable_label, 
        mirror=True, 
        ticks='outside', 
        showline=True, 
        linewidth=2, 
        linecolor='black', 
        row=1, 
        col=1)
    fig.update_yaxes(
        title_text=quantity_label, mirror=True, 
        ticks='outside', 
        showline=True, 
        linewidth=2, 
        linecolor='black', 
        nticks = 5,
        row=1, 
        col=1)
    for i, trace in enumerate(fig.data):
      trace.update(marker=marker_sequence[i])

    fig.update_layout(**default_layout)
    fig.update_layout(**layout)
    fig.show()
    fig.write_image(fig_fpath, format = 'pdf')

def get_sampler_name(division): 
    return 'fl {} 10000 0'.format(division)

def flatten(
    df_by_reduction_factor, 
    reduction_factors = REDUCTION_FACTORS): 

    flattened = [[], []]
    for reduction_factor in reduction_factors: 
      sampler_name = get_sampler_name(reduction_factor)
      print(df_by_reduction_factor[sampler_name].tolist())
      values = df_by_reduction_factor[sampler_name].tolist()
      flattened[0] += [reduction_factor for v in values]
      flattened[1] += values
    
    return flattened

def plot_dash_by_reduction_factor(
    dfs = [opt_gap, size_expansion], 
    quantity_labels = ['Optimality gap (%)', 'Size expansion (times)'], 
    chart_types = ['mean', 'mean'], 
    reduction_factors = REDUCTION_FACTORS, 
    log_scale = False, 
    fig_fpath = "fig.pdf", 
    sampler_names = default_sampler["sampler_names"], 
    sampler_labels = default_sampler["sampler_labels"], 
    layout = {},
    color_sequence = default_color_sequence,
    marker_sequence = default_marker_sequence,
    verbose = False # Print out the chart data for debugging
  ): 
    
    sampler_names = [get_sampler_name(reduction_factor) for reduction_factor in reduction_factors]
    
    DEFAULT_FILTERS = {
        'num_node': 60, 
        'average_degree': 6, 
        'weight_range': 1024, 
        'weight_scale': 32
    }
    
    filter_str = ''
    for filter_key in DEFAULT_FILTERS.keys(): 
        if len(filter_str) > 0: 
            filter_str += ' and '
        filter_str += filter_key + ' == ' + str(DEFAULT_FILTERS[filter_key])
            
    print("Filter string: ", filter_str)
    dfs_by_reduction_factor = [df.query(filter_str)[sampler_names] for df in dfs] # columns of qubits/energy/time are now sorted by the order of sampler_name = the order of Slicing factor
    print(dfs_by_reduction_factor)
    
    dfs_mean = [df_by_reduction_factor.aggregate('mean') for df_by_reduction_factor in dfs_by_reduction_factor]
    dfs_scatter = [flatten(df_by_reduction_factor) for df_by_reduction_factor in dfs_by_reduction_factor]

    for df_mean in dfs_mean: 
      print("df_mean: ", df_mean.values.flatten().tolist())
    
    fig = sp.make_subplots(
        rows=1, 
        cols=1, 
        specs=[[{"secondary_y": True}]]
    )

    for i, (df_mean, df_scatter, chart_type) in enumerate(zip(dfs_mean, dfs_scatter, chart_types)): 
      fig.add_trace(
          go.Scatter(
              x = reduction_factors if chart_type == 'mean' else df_scatter[0], 
              y=df_mean.values.flatten().tolist() if chart_type == 'mean' else df_scatter[1], 
              mode='lines+markers' if chart_type == 'mean' else 'markers', 
              name=quantity_labels[i]
            ), 
          row=1, 
          col=1, 
          secondary_y = (i == 1)
      )

    fig.update_xaxes(
        title_text='Slicing factor', 
        mirror=True, 
        ticks='outside', 
        showline=True, 
        linewidth=2, 
        linecolor='black', 
        row=1, 
        col=1)
    for i in range(2): 
      fig.update_yaxes(
          title_text=quantity_labels[i], 
          ticks='outside', 
          showline=True, 
          linewidth=2,                   
          nticks=5,
          linecolor='black',
          row=1, 
          col=1, 
          secondary_y = (i == 1)
        )
    for i, trace in enumerate(fig.data):
      trace.update(marker=marker_sequence[i])
    # if log_scale: 
    #   fig.update_xaxes(type='log', dtick=0.30102999566)
    #   fig.update_yaxes(type='log', dtick=0.30102999566, secondary_y = False)
    #   fig.update_yaxes(type='log', dtick=0.30102999566, secondary_y = True)
    fig.update_layout(**default_layout)
    fig.update_layout(**layout)

    

    if verbose:
      print(fig.data)

    fig.show()
    fig.write_image(fig_fpath, format = 'pdf')


plot_dash_by_reduction_factor(
    fig_fpath = "plots/tradeoff_log_scale.pdf", 
    log_scale=True,
    layout = {"colorway":default_color_sequence[4:], 
              "legend": dict(
                yanchor="top",
                y=0.99,
                xanchor="left",
                x=0.09
                )},
    marker_sequence= default_marker_sequence[3:]
)

# print(plotly.io.orca.config)

plot_all_solvers(
    df=opt_gap, 
    variable_name='num_node', 
    variable_label='Number of variables', 
    quantity_label = 'Optimality gap (%)', 
    chart_types = ['scatter', 'scatter', 'mean'], 
    fig_fpath="plots/opt_gap_num_node.pdf",
    )

plot_all_solvers(
    df=opt_gap, 
    variable_name='average_degree', 
    variable_label='Average degree', 
    quantity_label = 'Optimality gap (%)', 
    chart_types = ['scatter', 'scatter', 'mean'], 
    fig_fpath="plots/opt_gap_avg_deg.pdf",
    layout = {"legend": dict(font=dict(size=32), bgcolor='rgba(0,0,0,0)')}
)

plot_all_solvers(
    df=running_times, 
    variable_name='num_node', 
    variable_label='Number of variables', 
    quantity_label = 'Running time (s)', 
    chart_types=['mean', 'mean', 'mean'], 
    fig_fpath="plots/run_time_num_node.pdf"
)

plot_all_solvers(
    df=running_times, 
    variable_name='average_degree', 
    variable_label='Average degree', 
    quantity_label = 'Running time (s)', 
    chart_types=['mean', 'mean', 'mean'], 
    fig_fpath="plots/run_time_avg_deg.pdf"
)

plot_all_solvers(
    df=qubits, 
    variable_name='num_node', 
    variable_label='Number of variables', 
    quantity_label = 'Embedded sizes (qubits)', 
    chart_types=['mean', 'mean',], 
    sampler_names=[ 'fl 11 10000 0', 'dwave'], 
    sampler_labels=[ 'HamSlicing+QA','QA'], 
    fig_fpath="plots/qubits_num_node.pdf"
)

plot_all_solvers(
    df=qubits, 
    variable_name='average_degree', 
    variable_label='Average degree', 
    quantity_label = 'Embeded size (qubits)', 
        chart_types=['mean', 'mean'], 
    sampler_names=['fl 11 10000 0','dwave'], 
    sampler_labels=['HamSlicing+QA', 'QA'], 
    fig_fpath="plots/qubits_avg_deg.pdf"
)

plot_dash_by_reduction_factor(
    fig_fpath = "plots/tradeoff_log_scale.pdf", 
    layout = {"colorway":default_color_sequence[4:], 
              "legend": dict(
                yanchor="top",
                y=0.99,
                xanchor="left",
                x=0.09
                )},
    marker_sequence= default_marker_sequence[3:],
    log_scale=True
)

plot_dash_by_reduction_factor(
    fig_fpath = "plots/tradeoff_linear_scale.pdf", 
    layout = {"colorway":default_color_sequence[4:], 
              "legend": dict(
                yanchor="top",
                y=0.99,
                xanchor="left",
                x=0.09
                )},
    marker_sequence= default_marker_sequence[3:],
    log_scale=False
)

